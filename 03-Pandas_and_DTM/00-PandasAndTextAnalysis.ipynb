{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Pandas and Text Analysis\n",
    "\n",
    "We have learned how to work with numbers in the Python package pandas, and how to work with text in Python using built in Python packages, and later the NLTK package. To operationalize concepts and analyze the numbers, we can combine these two packages together.\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "* Begin to think about how we can quantify text to use the output in further analyses, or to visualize the output\n",
    "* Learn how to add text analysis techniques to a pandas dataframe\n",
    "* Learn a few more visualization techniques\n",
    "* Learn a number of new pandas functions:\n",
    "    * the pandas apply function\n",
    "    * the pandas tolist function\n",
    "    * the pandas lambda function\n",
    "* Learn a new built-in function, the .join() function\n",
    "\n",
    "### Outline\n",
    "\n",
    "* [Text as a column in a pandas df](#df)\n",
    "* [Descriptive statistics and visualization](#stats)\n",
    "* [The str attribute](#str)\n",
    "* [The apply function](#apply)\n",
    "* [The lambda function](#lambda)\n",
    "* [Extracting text](#extract)\n",
    "* [Exercise: average TTR](#exercise)\n",
    "\n",
    "### Key Terms\n",
    "* *categorical variable*\n",
    "    * is a variable that can take on one of a limited, and usually fixed, number of possible values\n",
    "* *lambda function*\n",
    "    * syntax that allows us to write and apply our own function in a pandas dataframe\n",
    "* *x-axis*\n",
    "    * the horizontal axis of a graph\n",
    "* *y-axis*\n",
    "    * the vertical axis of a graph\n",
    "* *error bars*\n",
    "    * a graphical representation of the variability of data and are used on graphs to indicate the error, or uncertainty in a reported measurement. They give a general idea of how precise a measurement is, or conversely, how far from the reported value the true (error free) value might be.\n",
    "* *standard deviation*\n",
    "    * a measure that is used to quantify the amount of variation or dispersion of a set of data values\n",
    "* *join function*\n",
    "    * ''.join(), joins the elements in a list into one string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='df'></a>\n",
    "### 0. Create a DF from a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen texts in the form of raw text. Today we'll deal with text that is in the form of a .csv file. We can read it into Python in the same way we read in the numerical dataset from the National Survey of Family Growth. \n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "I created a .csv file from a collection of 19th century children's literature. The data were compiled by students in this course: http://english197s2015.pbworks.com/w/page/93127947/FrontPage\n",
    "\n",
    "The raw data are found here: http://dhresourcesforprojectbuilding.pbworks.com/w/page/69244469/Data%20Collections%20and%20Datasets#demo-corpora\n",
    "\n",
    "That page has additional corpora, so search through it to see if anything sparks your interest.\n",
    "\n",
    "I did some minimal cleaning to get the children's literature data in .csv format for our use. The delimiter for this file is a tab, so technically it's a tab separated file, or tsv. We can specify that delimiter with the option \"sep = '\\t'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt #note this last import statement. Why might we use \"import as\"?\n",
    "\n",
    "#read in our data\n",
    "df = pandas.read_csv(\"../data/childrens_lit.csv.bz2\", sep = '\\t', encoding = 'utf-8', compression = 'bz2', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this is a typical dataframe, possibly with more columns as strings than numbers. The text in contained in the column 'text'.\n",
    "\n",
    "Notice also there are missing texts. For now, we will drop these texts so we can move forward with text analysis. In your own work, you should justify dropping missing texts when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ex: Print the first text in the dataframe (starts with \"A DOG WITH A BAD NAME\"). \n",
    "###Hint: Remind yourself about the syntax for slicing a dataframe\n",
    "\n",
    "print(df.iloc[0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stats'></a>\n",
    "### 1. Descriptive Statistics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we probably want to do is describe our data, to make sure everything is in order. We can use the describe function for the numerical data, and the value_counts function for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe()) #get descriptive statistics for all numerical columns\n",
    "print()\n",
    "print(df['author gender'].value_counts()) #frequency counts for categorical data\n",
    "print()\n",
    "print(df['year'].value_counts()) #treat year as a categorical variable\n",
    "print()\n",
    "print(df['year'].mode()) #find the year in which the most novels were published"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a few things by just using the metadata already present.\n",
    "\n",
    "For example, we can use the groupby and the count() function to graph the number of books by male and female authors. This is similar to the value_counts() function, but allows us to plot the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat a pandas object that is a groupby dataframe, grouped on author gender\n",
    "grouped_gender = df.groupby(\"author gender\")\n",
    "print(grouped_gender['text'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's graph the number of texts by gender of author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gender['text'].count().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex: Create a variable called 'grouped_year' that groups the dataframe by year.\n",
    "## Print the number of texts per year.\n",
    "\n",
    "grouped_year = df.groupby('year')\n",
    "grouped_year['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can graph this via a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_year['text'].count().plot(kind = 'line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! That doesn't look right! Python automatically converted the year to scientific notation. We can set that option to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ticklabel_format(useOffset=False) #forces Python to not convert numbers\n",
    "grouped_year['text'].count().plot(kind = 'line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't done any text analysis yet. Let's apply some of our text analysis techniques to the text, add columns with the output, and analyze/visualize the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='str'></a>\n",
    "### 2. The str attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, pandas has an attribute called 'str' which allows us to access Python's built-in string functions.\n",
    "\n",
    "For example, we can make the text lowercase, and assign this to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lc'] = df['text'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ex: create a new column, 'text_split', that contains the lower case text split into list. \n",
    "####HINT: split on white space, don't tokenize it.\n",
    "\n",
    "df['text_split'] = df['text_lc'].str.split()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='apply'></a>\n",
    "### 3. The apply function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply a function to each row. To get a word count of a text file we would take the length of the split string like this:\n",
    "\n",
    "```len(text_split)```\n",
    "\n",
    "If we want to do this on every row in our dataframe, we can use the apply() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['text_split'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average length of each novel in our data? With pandas, this is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(These are long novels!) We can also group and slice our dataframe to do further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ex: print the average novel length for male authors and female authors.\n",
    "###### What conclusions might you draw from this?\n",
    "\n",
    "###Ex: graph the average novel length by gender\n",
    "\n",
    "grouped_gender = df.groupby('author gender')\n",
    "print(grouped_gender['word_count'].mean())\n",
    "grouped_gender['word_count'].mean().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to put error bars on this? We can add a 'yerr' option to our graph, and use the std() calculation to add error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gender = df.groupby('author gender')\n",
    "grouped_gender['word_count'].mean().plot(kind = 'bar', yerr = grouped_gender['word_count'].std())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gold star exercise\n",
    "\n",
    "This one is a bit tricky. If you're not quite there, no worries! We'll work through it together.\n",
    "\n",
    "**Ex: plot the average novel length by year, with error bars. Your x-axis should be year, and your y-axis number of words.**\n",
    "\n",
    "HINT: Copy and paste what we did above with gender, and then change the necessary variables and options. By my count, you should only have to change one variable, and one graph option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your exercise solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lambda'></a>\n",
    "### 4. The lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to use nltk or list comprehension on the split text, we have to introduce one more Python trick: the lambda function. This simply allows us to write our own function to apply to each row in our dataframe. For example, we may want tokenize our text instead of splitting on the white space. To do this we can use the lambda function.\n",
    "\n",
    "Because of the length of the novels tokenizing the text takes a bit of time. We'll instead tokenize the title only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_new'] = df['title'].apply(nltk.word_tokenize)\n",
    "#df['tokens'] = df['title'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df[['tokens_new','tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this tokenized list we might want to, for example, remove punctuation. Again, we can use the lambda function, with list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens'].apply(lambda x: [word for word in x if word not in list(string.punctuation)])\n",
    "df['tokens_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extract'></a>\n",
    "### 5. Extracting Text from a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to extract the text from our dataframe, to do further analyses on the text only. We can do this using the tolist() function and the join() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels = df['text'].tolist()\n",
    "print(novels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn all of the novels into one long string\n",
    "cat_novels = ''.join(n for n in novels)\n",
    "print(cat_novels[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise'></a>\n",
    "### 6. Exercise: Average TTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivating Question: Is there a difference in the average TTR for male and female authors?**\n",
    "\n",
    "To answer this, go step by step.\n",
    "\n",
    "For computational reasons we will use the list we created by splitting on white spaces rather than tokenized text. So this is approximate only.\n",
    "\n",
    "We first need to count the token type in each novel. We can do this in two steps. First, create a column that contains a list of the unique token types, by applying the set function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ex: create a new column, 'text_type', which contains a list of unique token types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ex: create a new column, 'type_count', which is a count of the token types in each novel.\n",
    "##Ex: create a new column, 'ttr', which contains the type-token ratio for each novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ex: Print the average ttr by author gender\n",
    "##Ex: Graph this result with error bars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
