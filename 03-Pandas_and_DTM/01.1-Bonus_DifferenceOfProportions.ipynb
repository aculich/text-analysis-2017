{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bouns: Difference of proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple way to calculate distinctive words in two texts is to calculate the words with the highest and lowest difference or proportions. In theory frequent words like 'the' and 'of' will have a small difference. In practice this doesn't happen.\n",
    "\n",
    "To demonstrate this we will run a difference of proportion calculation on *Pride and Prejudice* and *A Garland for Girls*.\n",
    "\n",
    "To get the text in shape for scikit-learn we need to creat a list object with each novel as an element in a list. We'll use the append function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "#open and read the novels, save them as variables\n",
    "austen_string = open('../Data/Austen_PrideAndPrejudice.txt', encoding='utf-8').read()\n",
    "alcott_string = open('../Data/Alcott_GarlandForGirls.txt', encoding='utf-8').read()\n",
    "\n",
    "#append each novel to the list\n",
    "text_list.append(austen_string)\n",
    "text_list.append(alcott_string)\n",
    "print(text_list[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DTM from these two novels, force it into a pandas DF, and inspect the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer()\n",
    "novels_df = pandas.DataFrame(countvec.fit_transform(text_list).toarray(), columns=countvec.get_feature_names())\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the number of rows and columns.\n",
    "\n",
    "Question: What does this mean?\n",
    "\n",
    "Next, we need to get a word frequency count for each novel, which we can do by summing across the entire row. Note how the syntax is different here compared to when we summed one column across all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df['word_count'] = novels_df.sum(axis=1)\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we divide each frequency cell by the word count. This syntax gets a bit tricky, so let's walk through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df = novels_df.iloc[:,:].div(novels_df.word_count, axis=0)\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we subtract one row from another, and add the output as a third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df.loc[2] = novels_df.loc[0] - novels_df.loc[1]\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort based of the values of this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df.loc[2].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are still in there. Why?\n",
    "\n",
    "We can, of course, manually remove stop words. This does successfully identify distinctive content words. \n",
    "\n",
    "We can do this in the CountVectorizer step, by setting the correct option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change stop_words option to 'english\n",
    "countvec_sw = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "#same as code above\n",
    "novels_df_sw = pandas.DataFrame(countvec_sw.fit_transform(text_list).toarray(), columns=countvec_sw.get_feature_names())\n",
    "novels_df_sw['word_count'] = novels_df_sw.sum(axis=1)\n",
    "novels_df_sw = novels_df_sw.iloc[:,0:].div(novels_df_sw.word_count, axis=0)\n",
    "novels_df_sw.loc[2] = novels_df_sw.loc[0] - novels_df_sw.loc[1]\n",
    "novels_df_sw.loc[2].sort_values(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this by setting the max_df option (maximum document frequency) to either an absolute value, or a decimal between 0 and 1. An absolute value indicate that if the word occurs in more documents than the stated value, that word **will not** be included in the DTM. A decimal value will do the same, but proportion of documents.\n",
    "\n",
    "Question: In the case of this corpus, what does setting the max_df value to 1 do? What output do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change max_df option to 1\n",
    "countvec_freq = CountVectorizer(max_df=1)\n",
    "\n",
    "#same as the code above\n",
    "novels_df_freq = pandas.DataFrame(countvec_freq.fit_transform(text_list).toarray(), columns=countvec_freq.get_feature_names())\n",
    "novels_df_freq['word_count'] = novels_df_freq.sum(axis=1)\n",
    "novels_df_freq = novels_df_freq.iloc[:,0:].div(novels_df_freq.word_count, axis=0)\n",
    "novels_df_freq.loc[2] = novels_df_freq.loc[0] - novels_df_freq.loc[1]\n",
    "novels_df_freq.loc[2].sort_values(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What would happen if we set the max_df to 2, in this case?\n",
    "Question: What might we do for the music reviews dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Use the difference of proportions calculation to compare two genres, or two artists, in the music reviews dataset. There are many ways you can do this. Think through the problem in steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
